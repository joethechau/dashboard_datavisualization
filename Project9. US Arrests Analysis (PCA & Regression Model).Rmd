---
title: 'US Arrests Analysis (PCA & Regression Model)'
author: "MINHCHAU"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r load-libraries, echo=TRUE, warning = FALSE, message = FALSE}
library(dplyr)
library(tidyr)
library(car) 
library(psych) # for pairs.panels()
library(factoextra) # for fviz_cluster()
library(ggplot2)

```


Perform Principal Component Analysis (PCA), examine the results, and use the principal components in regression modeling.

**Principal Component Analysis (PCA)** is a statistical technique used to reduce the dimensionality of a dataset while retaining as much variance (or information) as possible. It achieves this by transforming the original features (variables) into a smaller set of uncorrelated variables called **principal components**. These components are ordered so that the first few components capture the most significant variation in the data.

Dataset required: `Arrests.csv`

(1a) Load the Dataset and read the Arrests.csv file into a dataframe called df. The **US Arrests** dataset contains data about the number of arrests per 100,000 residents for different crimes in each US state.

-   Use head() and names() functions to inspect the first few rows and column names of the dataset.

-   What are the names of the columns in the dataset?

-   Extract the columns Murder, Assault, UrbanPop, and Rape into a new dataframe called USArrests.


```{r, q1a-load dataset, echo=TRUE}
df = read.csv('Arrests.csv')
head(df)
names(df)
USArrests <- df[ , c('Murder', 'Assault', 'UrbanPop', 'Rape')]
```

(1b) Let's take a quick look at the column means and variance of the data. Compute the mean and standard deviation of each feature in USArrests using the apply() function. We can use the apply() function to apply a function - in this case, the mean() function - to each row or column of the data set.

-   What are the means and standard deviations of the features?

-   Comment on any differences in scale.

-   Standardize the variables to have a mean of zero and a standard deviation of one. Why is it important to center and scale the data before performing PCA?


```{r, q1b, echo=TRUE}
#mena and standard deviation of the features
apply(USArrests , 2, mean)
apply(USArrests , 2, sd)
#standardize the data
USArrests_scale <- scale(USArrests)

```

(1c) Perform PCA with centering and scaling. You can do this by setting center = TRUE and scale = TRUE in the `prcomp()` function.

-   View the summary of the PCA results, what percentage of variance is explained by the first two principal components?

A **scree plot** is a graphical representation that helps you determine how much variance is explained by each principal component.

-   Create a scree plot to visualize the results.

-   What do the scree plot reveal about the principal components?


```{r, q1c, echo=TRUE}
pr.out <- prcomp(~ Murder + Assault + UrbanPop + Rape, data=USArrests, center=TRUE, scale=TRUE)
#check the components of the prcomp object
names(pr.out)
summary(pr.out)
#scree plot
library(factoextra)
fviz_eig(pr.out)
```
::: {style="color: red"}
86.75% of variance is explained by the first 2 principal components
PC1: The 1st principal component explains about 62.01% of the proportion of variance
PC2: The 2nd principal component explains about 24.74% of the proportion of variance
PC3 and PC4: explains about 8.91% and 4.34% of the proportion of variance
:::

(1d) When you perform PCA, the goal is to find a set of new axes (principal components) that capture the maximum variance in the data. Each principal component is a linear combination of the original features (variables).

**Loading vectors** represent the coefficients of these linear combinations. In simple terms, a loading vector tells you how much each original variable "loads" or contributes to a particular principal component. Loading vectors defines a direction in feature space along which the data vary the most.

-   You can use the pr.out\$rotation to view the loadings for all principal components.

-   Extract and inspect the loadings for the first two principal components (`pc1` and `pc2`).

-   Provide the formula for PC1.

-   Add the first two principal component scores as new columns to the USArrests dataframe.

A **biplot** is a graphical representation that combines both the **scores** of the data points (the projections onto the principal components) and the **loadings** of the variables

-   Create a biplot to visualize the results.

-   What do the biplot reveal about the principal components?

```{r, q1d, echo=TRUE}
head(pr.out$x, 10)
USArrests$pc1 <- pr.out$x[, "PC1"]
USArrests$pc2 <- pr.out$x[, "PC2"]
biplot(pr.out, scale=0, xlabs=df$State)
```

Orientation of the vector: When a vector is parallel to a principal component axis, it means that the vector's direction closely follows that axis. This indicates that the vector contributes significantly to that particular principal component

::: {style="color: red"}
PC1: The 1st principal component roughly corresponds to a measure of overall rates of serious crimes
Interpretation: States with large negative scores on PC1, such as Florida, Nevada and California have high crime rates, while states like South Dakota ,with positive scores on PC1, have low crime rates
:::

(1e) How can you use the principal component scores for further
regression modeling?

-   Perform a regression analysis using the principal component scores (`pc1` and `pc2`).

-   Are the principal components significant in explaining the dependent variable (e.g., GDP) in this regression model?


```{r, q1e, echo=TRUE}
USArrests$GDP <- df$GDP.in.dollars
#Fit a linear regression model
summary(lm(GDP ~ pc1+pc2, data=USArrests))

```

::: {style="color: red"}
Since the p-value for pc1 = 0.00652 < 0.05 and pc2 = 0.0265 < 0.05, both the principal components are significant at 5% level of significance to the GDP in this regression model
:::
